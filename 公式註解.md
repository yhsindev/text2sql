＃uncover the impact of CoT in DPO 公式註解

### 字母含义
- **$\mathcal{L}_{SFT}$**: 表示监督式微调（Supervised Fine-Tuning, SFT）的损失函数，用于衡量模型在监督式微调过程中的预测误差，其值越小，说明模型预测结果与真实结果越接近。
- **$\mathbb{E}$**: 代表数学期望（Expected value），是一个统计学概念。在这里，它表示对符合$(q, d, c)\sim D_S$分布的所有样本取平均。
- **$(q, d, c)$**: 表示一个样本，其中：
    - **$q$**: 表示问题（Question），即文本转SQL任务中输入的自然语言问题。
    - **$d$**: 表示数据库提示（Database prompt），与数据库相关的信息提示，辅助模型生成合适的SQL语句。
    - **$c$**: 表示输出的思维链（Chain-of-Thought, CoT）解决方案，也就是模型生成的解题过程。
- **$\sim$**: 表示“服从某种分布”，这里$(q, d, c)\sim D_S$表示样本$(q, d, c)$服从$D_S$所代表的分布。
- **$D_S$**: 表示CoT增强训练集（CoT-enhanced training set），是经过思维链增强后的训练数据集合，用于监督式微调训练。
- **$\log$**: 自然对数函数，在公式中用于计算概率的对数。
- **$\pi_{base}$**: 指基础模型（Base model），即未经微调的原始大语言模型，这里$\pi_{base}(c|q, d)$表示在给定问题$q$和数据库提示$d$的条件下，基础模型生成CoT解决方案$c$的概率分布。

### 公式整体含义
该公式用于计算监督式微调（SFT）过程中的损失。它通过对CoT增强训练集$D_S$中的所有样本$(q, d, c)$求平均，计算基础模型在给定$q$和$d$时生成正确$c$的概率的对数的期望值，并取其相反数。训练的目标就是最小化这个损失函数$\mathcal{L}_{SFT}$，使得模型在面对问题$q$和数据库提示$d$时，能够以更高的概率生成正确的CoT解决方案$c$。

### 公式各部分组合含义
- **$\log\pi_{base}(c|q, d)$**: 计算在给定问题$q$和数据库提示$d$的条件下，基础模型生成特定CoT解决方案$c$的概率的自然对数。通过取对数，将概率值转换到对数空间，便于计算和优化，同时也能放大较小概率之间的差异，使得模型更关注那些不太可能但正确的输出。
- **$\mathbb{E}_{(q,d,c)\sim D_S}[\log\pi_{base}(c|q, d)]$**: 对CoT增强训练集$D_S$中所有样本的$\log\pi_{base}(c|q, d)$求数学期望，也就是求平均。这一步是为了综合考虑训练集中所有样本的情况，得到一个总体的、能反映模型在整个训练集上预测效果的指标。
- **$-\mathbb{E}_{(q,d,c)\sim D_S}[\log\pi_{base}(c|q, d)]$**: 对上述期望取负号。因为在优化过程中，我们通常希望损失函数越小越好，而概率的对数在$0$到$1$之间取值时是负数，取负后就变成了正数，这样损失函数值越小就代表模型预测越准确。

![image-20250420231012083](C:\Users\29845\AppData\Roaming\Typora\typora-user-images\image-20250420231012083.png)

### 字母及符号含义
- **$\mathcal{L}_{DPO}$**: 代表直接偏好优化（Direct Preference Optimization, DPO）的损失函数。其作用是衡量模型在直接偏好优化过程中的预测误差，在模型训练中，目标是最小化该损失函数，以提升模型性能。值越小，表示模型预测结果与期望结果越接近。
- **$\mathbb{E}$**: 表示数学期望（Expected value）。在这里，是对符合$(q, d, c^+, c^-)\sim D_P$分布的所有样本求平均，用于综合考虑训练集中所有相关样本的情况。
- **$(q, d, c^+, c^-)$**: 表示一个样本相关的元素集合，其中：
    - **$q$**: 表示问题（Question），即文本转SQL任务中输入的自然语言问题。
    - **$d$**: 表示数据库提示（Database prompt），提供与数据库相关的信息，辅助模型生成合适的SQL语句。
    - **$c^+$**: 表示正确的思维链（Chain-of-Thought, CoT）解答，是模型针对问题$q$和数据库提示$d$生成的正确解题过程。
    - **$c^-$**: 表示错误的思维链（CoT）解答，是模型针对问题$q$和数据库提示$d$生成的错误解题过程。
- **$\sim$**: 表示"服从某种分布"，这里$(q, d, c^+, c^-)\sim D_P$表示样本$(q, d, c^+, c^-)$服从$D_P$所代表的分布。
- **$D_P$**: 代表偏好数据集（Preference dataset），是用于直接偏好优化训练的数据集合，其中包含了问题$q$、数据库提示$d$以及对应的正确和错误CoT解答$c^+$和$c^-$。
- **$\log$**: 自然对数函数，在公式中用于计算概率相关的对数，将概率值转换到对数空间，便于计算和优化。
- **$\sigma$**: 通常指Sigmoid函数，其作用是将输入值压缩到$0$到$1$之间，在这里用于将对数概率的差值转换为一个概率值，表示模型更偏好正确解答$c^+$而非错误解答$c^-$的概率。
- **$\beta$**: 是一个超参数，用于调整模型对不同解答的区分敏感度。它控制着正确解答和错误解答对数概率差值的权重，影响模型在优化过程中对正确与错误解答的区分程度。
- **$\pi_{DPO}$**: 表示经过直接偏好优化后的模型，$\pi_{DPO}(c^+|q, d)$表示在给定问题$q$和数据库提示$d$的条件下，DPO模型生成正确CoT解答$c^+$的概率分布；$\pi_{DPO}(c^-|q, d)$表示在给定问题$q$和数据库提示$d$的条件下，DPO模型生成错误CoT解答$c^-$的概率分布。
- **$\pi_{SFT}$**: 表示经过监督式微调（SFT）后的模型，$\pi_{SFT}(c^+|q, d)$表示在给定问题$q$和数据库提示$d$的条件下，SFT模型生成正确CoT解答$c^+$的概率分布；$\pi_{SFT}(c^-|q, d)$表示在给定问题$q$和数据库提示$d$的条件下，SFT模型生成错误CoT解答$c^-$的概率分布。

### 公式整体含义
该公式用于计算直接偏好优化（DPO）过程中的损失。它通过对偏好数据集$D_P$中的所有样本$(q, d, c^+, c^-)$求平均，利用Sigmoid函数$\sigma$来计算模型更偏好正确解答$c^+$而非错误解答$c^-$的概率的对数，再取其相反数。在模型训练时，目标是最小化这个损失函数$\mathcal{L}_{DPO}$，使得模型能够更好地区分正确和错误的CoT解答，提高生成正确解答的概率。

### 公式各部分组合含义
- **$\log \frac{\pi_{DPO}(c^+|q, d)}{\pi_{SFT}(c^+|q, d)}$和$\log \frac{\pi_{DPO}(c^-|q, d)}{\pi_{SFT}(c^-|q, d)}$**: 分别计算DPO模型相对于SFT模型，生成正确解答$c^+$和错误解答$c^-$的概率比值的对数。这一步是为了衡量DPO模型相较于SFT模型在生成正确和错误解答上的变化情况，反映DPO优化对模型输出概率分布的影响。
- **$\beta \log \frac{\pi_{DPO}(c^+|q, d)}{\pi_{SFT}(c^+|q, d)} - \beta \log \frac{\pi_{DPO}(c^-|q, d)}{\pi_{SFT}(c^-|q, d)}$**: 通过超参数$\beta$对上述两个对数概率比值进行加权，然后求差值。这个差值表示DPO模型在超参数$\beta$的作用下，对正确解答和错误解答区分能力的量化指标，体现了DPO优化希望模型更倾向于生成正确解答的意图。
- **$\log \sigma \left(\beta \log \frac{\pi_{DPO}(c^+|q, d)}{\pi_{SFT}(c^+|q, d)} - \beta \log \frac{\pi_{DPO}(c^-|q, d)}{\pi_{SFT}(c^-|q, d)}\right)$**: 将上述差值输入到Sigmoid函数$\sigma$中，将其转换为$0$到$1$之间的概率值，表示模型更偏好正确解答$c^+$而非错误解答$c^-$的概率，再取对数进一步调整数值范围和特性，以便于在损失计算中更好地反映模型的偏好程度。
- **$-\mathbb{E}_{(q,d,c^+,c^-)\sim D_P} \log \sigma \left(\beta \log \frac{\pi_{DPO}(c^+|q, d)}{\pi_{SFT}(c^+|q, d)} - \beta \log \frac{\pi_{DPO}(c^-|q, d)}{\pi_{SFT}(c^-|q, d)}\right)$**: 对偏好数据集$D_P$中所有样本的上述对数概率值求数学期望并取负。求期望是为了综合考虑整个数据集上模型的偏好情况，取负是因为在优化中希望损失函数越小越好，通过最小化这个损失函数，促使模型优化自身参数，提高区分正确和错误解答的能力。
